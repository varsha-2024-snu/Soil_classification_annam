{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Soil Type Classification - Project Card\n",
        "\n",
        "## Project Overview\n",
        "This project is part of the **Kaggle Soil Classification Challenge (2025)**. The goal is to classify images of soil into one of the following four categories:\n",
        "\n",
        "- **Alluvial soil**\n",
        "- **Black Soil**\n",
        "- **Clay soil**\n",
        "- **Red soil**\n",
        "\n",
        "We used a ResNet34 deep learning model trained on labeled soil images to predict the soil type for a test set.\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset\n",
        "The dataset was provided by the competition organizers and contains:\n",
        "- `train_labels.csv`: Contains image IDs and their corresponding soil types.\n",
        "- `train/`: Folder containing training images.\n",
        "- `test_ids.csv`: Contains image IDs for testing.\n",
        "- `test/`: Folder containing test images (some in `.gif` or `.webp` format).\n",
        "\n",
        "We performed preprocessing to:\n",
        "- Normalize and resize images to 224x224.\n",
        "- Apply augmentations like rotation, flipping, and color jitter.\n",
        "- Convert unsupported formats (.gif, .webp) to `.jpg`.\n",
        "\n",
        "---\n",
        "\n",
        "## Model Architecture\n",
        "- **Backbone:** ResNet34 pretrained on ImageNet.\n",
        "- Final fully connected layer was replaced with: `nn.Linear(in_features=512, out_features=4)`.\n",
        "\n",
        "### Loss & Optimization\n",
        "- **Loss Function:** CrossEntropyLoss\n",
        "- **Optimizer:** Adam (`lr=1e-4`)\n",
        "- **Scheduler:** StepLR (step size = 5, gamma = 0.5)\n",
        "\n",
        "---\n",
        "\n",
        "##\n",
        "Training and Validation\n",
        "We split the data into **80% training** and **20% validation** using stratified sampling.\n",
        "\n",
        "### Training Details:\n",
        "- **Epochs:** 15\n",
        "- **Batch size:** 32\n",
        "- **Device:** GPU (if available)\n",
        "\n",
        "### Final Epoch Metrics:\n",
        "```plaintext\n",
        "Epoch 15/15\n",
        "  ➤ Train Loss: 0.0250\n",
        "  ➤ Per-class F1: [0.9714, 0.9787, 0.9367, 0.9903]\n",
        "  ➤ Min F1: 0.9367\n"
      ],
      "metadata": {
        "id": "8WAI9fsVm-iM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "\n",
        "- **Backbone**: ResNet34 with pretrained ImageNet weights.\n",
        "- **Modification**: Final FC layer replaced with a new `Linear(in_features, 4)` for 4 soil classes.\n",
        "- **Loss Function**: CrossEntropyLoss\n",
        "- **Optimizer**: Adam with learning rate `1e-4`\n",
        "- **Learning Rate Scheduler**: StepLR (step size = 5, gamma = 0.5)\n",
        "\n",
        "---\n",
        "\n",
        "## Training & Evaluation\n",
        "\n",
        "- Training done on an 80-20 train-validation split.\n",
        "- Data augmentation applied for robust generalization:\n",
        "  - Horizontal Flip\n",
        "  - Random Rotation\n",
        "  - Color Jitter\n",
        "- Validation used minimal transformation for consistent evaluation.\n",
        "\n",
        "### Final Epoch Metrics (Epoch 15 of 15):\n",
        "\n",
        "- **Train Loss**: `0.0250`\n",
        "- **Per-Class F1 Scores**:\n",
        "  - Alluvial soil: `0.9714`\n",
        "  - Black Soil: `0.9787`\n",
        "  - Clay soil: `0.9367`\n",
        "  - Red soil: `0.9903`\n",
        "- **Minimum F1**: `0.9367`\n",
        "\n",
        "---\n",
        "\n",
        "## Test Inference Pipeline\n",
        "\n",
        "- Test image formats handled: `.jpg`, `.jpeg`, `.png`, `.webp`, `.gif`\n",
        "- Images were preprocessed and converted to `.jpg` if needed.\n",
        "- The trained model was reloaded and used to predict soil types on test images.\n",
        "- Final predictions were mapped back to class names using the inverse label map.\n",
        "\n",
        "---\n",
        "\n",
        "##  Output\n",
        "\n",
        "- `submission.csv` generated with **100% test coverage**.\n",
        "- Format:  \n",
        "  ```csv\n",
        "  image_id,soil_type\n",
        "  xyz.jpg,Clay soil\n",
        "  abc.jpg,Red soil\n",
        "  ...\n"
      ],
      "metadata": {
        "id": "yBMAOC7vnh8R"
      }
    }
  ]
}